{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb803f7-d2f3-422e-9c31-2d4c1a46ec2b",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 60%\">\n",
    "       <img src=\"https://dca.cat/wp-content/uploads/2022/05/Noticies-web-DCA-3.png\", align=\"left\", width=\"250\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 40%;\">\n",
    "    <p style=\"margin: 0; text-align:right;\">SIGTE - University of Girona</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Geopython 2024</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Josep Sitjar</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Toni Hern√°ndez</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd0497-c26a-44e4-8ea7-9bf1b682d6a9",
   "metadata": {},
   "source": [
    "An introduction to image processing with Python \n",
    "=================================================\n",
    "\n",
    "Earth Observation satellites offer a multitude of images daily. The workshop will cover the different steps of a remote sensing project using Python libraries.\n",
    "\n",
    "A remote sensing project includes several processes: search, filter and download available images from a certain area, but also visualize and analyze them to extract valuable information.\n",
    "\n",
    "The use of Python libraries is very useful to successfully accomplish all this tasks. In that sense, the workshop will start with the development of Python scripts using libraries like earthaccess and landsatxplore in order to search and obtain images from the Landsat and Copernicus program APIs.\n",
    "\n",
    "Once the images are obtained, it's usually necessary to visualize them on a plot. Different band combinations in true and false color can be performed, and Python libraries like earthpy and matplotlib can help in that task.\n",
    "\n",
    "Finally, the last part of the workshop will introduce image analysis like band operations to calculate vegetation indices, but also image classification techniques to identify land coverages.\n",
    "\n",
    "During the workshop, assistants will code the scripts in a jupyter notebook, but also we'll use Spyder, a very powerful environment for data scientists to write and run Python scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b52d03-6222-4248-a2a7-fed5afb65b07",
   "metadata": {},
   "source": [
    "\n",
    "## Chapter 1: Access to satellite images \n",
    "\n",
    "\n",
    "This chapter of the workshop will cover the image acquisition from Sentinel and Landsat programmes.\n",
    "\n",
    "[Earth Explorer](https://earthexplorer.usgs.gov) or [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu) offer interactive tools to search and download images from these satellites. However, Python scripts with libraries such as **Landsatxplore** or interacting with API's like **OpenSearch** make this task easier. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927a38f0-ca50-4bd4-bf7a-7f61e17cabc1",
   "metadata": {},
   "source": [
    "### Search and download Landsat images with Landsatxplore \n",
    "\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 60%\">\n",
    "       <img src=\"https://www.satellitetoday.com/wp-content/uploads/2018/03/landsat_9_in_space__update.jpg\", align=\"left\", width=\"250\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e3934-f3b1-49ab-a706-13cc09a31538",
   "metadata": {},
   "source": [
    "---\n",
    "**NOTE**\n",
    "\n",
    "If you don't have access credentials to Earth Explorer, you can create an account through [Earth Explorer](https://earthexplorer.usgs.gov/  ) website. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41de22-b2a5-4118-8441-bdb4c7577ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the landsatxplore library \n",
    "%pip install landsatxplore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76065715-9576-41d2-b6e7-10caaa0beb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install python-dotenv to manage passwords \n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d6ea8-0924-4d5b-a0e0-27270b055786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from landsatxplore.api import API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b85f3-d8f8-4b54-9834-f88f18be5df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials from .env file in same folder\n",
    "load_dotenv() \n",
    "lsxpl_usr = os.getenv('usr_earth_access')\n",
    "lsxpl_pswd = os.getenv('pswd_earth_access')\n",
    "\n",
    "# Initialize API instance with Earth Explorer credentials \n",
    "api = API(lsxpl_usr, lsxpl_pswd)\n",
    "\n",
    "# Search Landsat scene from specific location (lat, lng) and dta range. \n",
    "scenes = api.search(\n",
    "    dataset='landsat_ot_c2_l1',\n",
    "\tlatitude=41.983,\n",
    "\tlongitude=2.824,\n",
    "\tstart_date='2023-08-01',\n",
    "\tend_date='2023-08-31',\n",
    "\tmax_cloud_cover=30\n",
    ")\n",
    "\n",
    "print(f\"{len(scenes)} scenes found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf273c4-5222-4954-ab0b-c7c45815f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's also possible to search for a scene based on it's bbox\n",
    "\n",
    "scenes = api.search(\n",
    "    dataset='landsat_ot_c2_l1',\n",
    "\tbbox= [1.456,40.688,4.256,42.815],\n",
    "\tstart_date='2023-08-01',\n",
    "\tend_date='2023-08-31',\n",
    "\tmax_cloud_cover=30\n",
    ")\n",
    "\n",
    "print(f\"{len(scenes)} scenes found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12dc30d-3f55-4df2-8488-1d0a5e00f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show scene metadata \n",
    "for scene in scenes:\n",
    "    print(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23540d7-c0ad-47f2-866c-da40292f0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show scene information, such as acquisiton date. \n",
    "for scene in scenes:\n",
    "    print(scene['acquisition_date'].strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130f91b-d4b7-439d-9520-e0f533957e0a",
   "metadata": {},
   "source": [
    "Scene metadata contains informatin about it's spatial coverage, or what is the same, it's footprint. \n",
    "From this geometry we can ceate a GeoJson file and save it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd1da1-c7f0-4184-bb62-f0eaeb55b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene in scenes:\n",
    "\t# Acquisition date\n",
    "\tprint(scene['acquisition_date'].strftime('%Y-%m-%d'))\n",
    "\t# Create GeoJson file \n",
    "\tfname = f\"{scene['landsat_product_id']}.geojson\"\n",
    "\twith open(fname, \"w\") as f:\n",
    "\t\tjson.dump(scene['spatial_coverage'].__geo_interface__, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23396e73-16fb-4019-aec5-9dff9a968b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usig folium, we can visualize the footprints over an interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44dea8-cb26-480b-af0f-de6b4bdb1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316d82d-1d44-4083-a1d3-fe2ea0404008",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The footprint of one scene \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46b1e7-f45f-4f21-9892-71d6411c288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium \n",
    "\n",
    "# Geometry of a single scene\n",
    "geom = scenes[0]['spatial_coverage'].__geo_interface__\n",
    "\n",
    "# Create a Map, with a location and zoom\n",
    "m = folium.Map(location=[41.983, 2.824], zoom_start=5)\n",
    "\n",
    "# Style of the geometry\n",
    "style = {'fillColor': 'red', 'color': 'blueviolet'}\n",
    "\n",
    "# Add the GeoJson to the map\n",
    "folium.GeoJson(data = geom, name = \"geojson\",\n",
    "    style_function = lambda x:style).add_to(m)\n",
    "\n",
    "# Load the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebd1c8-bbec-41b5-b049-07246e48c347",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The footprint of multiple scenes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c8225f-d995-4cca-847b-4d0eda24c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721ceed-cf09-43b4-9163-6e520f6da367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, MultiPolygon \n",
    "\n",
    "m = folium.Map(location=[41.983, 2.824], zoom_start=5)\n",
    "\n",
    "for scene in scenes:\n",
    "    geom = scene['spatial_coverage'].__geo_interface__\n",
    "    \n",
    "    # Style of the geometry\n",
    "    style = {'fillColor': 'red', 'color': 'blueviolet'}\n",
    "    \n",
    "    # Add the GeoJson to the map\n",
    "    folium.GeoJson(data = geom, name = \"geojson\",\n",
    "        style_function = lambda x:style).add_to(m)\n",
    "\n",
    "# Load the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9dcee3-1e32-4086-acbd-cb962de2938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download scene using EarthExplorer \n",
    "#from landsatxplore.earthexplorer import EarthExplorer\n",
    "\n",
    "#ee = EarthExplorer(lsxpl_usr, lsxpl_pswd)\n",
    "#ee.download('LC09_L2SP_197031_20230810_20230812_02_T1', output_dir='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817d437-8f4b-4d0d-b2a7-70010875a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection with EarthExplorer \n",
    "#ee.logout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a023590-fe4f-4566-a56b-268bfb3a4c35",
   "metadata": {},
   "source": [
    "### Search and download images with Earthaccess\n",
    "\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 60%\">\n",
    "       <img src=\"https://user-images.githubusercontent.com/717735/205517116-7a5d0f41-7acc-441e-94ba-2e541bfb7fc8.png\", align=\"left\", width=\"250\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd28529-a5aa-4e09-8960-ce957c788d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install earthaccess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f459a5-b96f-40ff-90ae-68479bdb48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess \n",
    "from earthaccess import Auth, Store, DataCollections, DataGranules\n",
    "\n",
    "# Login to earthaccess with NASA Earthdata Login (EDL)\n",
    "auth = earthaccess.login()\n",
    "\n",
    "# Search data from HLSL30 collection \n",
    "Query = earthaccess.granule_query().short_name('HLSL30').bounding_box(2.779,41.942,2.857,42.001).temporal(\"2023-08-01\",\"2023-08-31\")\n",
    "# Show results \n",
    "granules = Query.get()\n",
    "[display(g) for g in granules]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1968548-d225-43f6-9457-09b3bafaa9f6",
   "metadata": {},
   "source": [
    "### Search and download Sentinel images with OpenSearch API \n",
    "\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 60%\">\n",
    "       <img src=\"https://gisgeography.com/wp-content/uploads/2018/03/sentinel-satellites-copernicus-programme-1-768x431.png\", align=\"left\", width=\"250\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a62f53-6b5c-40fb-be02-889eb5b30c59",
   "metadata": {},
   "source": [
    "OpenSearch is an API to access the copernicus data catalog. \n",
    "Currently, there's not any open source Python library to interact with this API, so we'll use Requests to make the queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b502c6f-e565-4ef9-9bea-3c5426dc02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install geopandas \n",
    "%pip install geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a71cd-7f08-4859-a1a6-4977f74f5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import json \n",
    "import geojson \n",
    "\n",
    "# Search parameters for OpenSearch API\n",
    "start_date = \"2023-08-01\"\n",
    "end_date = \"2023-08-31\"\n",
    "cloud_coverage = [0,10]\n",
    "west = 2.798795\n",
    "south = 41.955166\n",
    "east = 2.845486\n",
    "north = 42.009271\n",
    "collection = \"SENTINEL-2\"\n",
    "\n",
    "# Search metadata of available images\n",
    "json_data = requests.get(f\"https://catalogue.dataspace.copernicus.eu/resto/api/collections/Sentinel2/search.json?productType=S2MSI2A&cloudCover={cloud_coverage}&startDate={start_date}&completionDate={end_date}&maxRecords=20&box={west},{south},{east},{north}\").json()\n",
    "\n",
    "# Convert json to GeoPandas DataFrame in order to improve data management\n",
    "df = pd.DataFrame.from_dict(json_data['features'])\n",
    "\n",
    "# Iterate over results \n",
    "for index, row in df.iterrows():\n",
    "    print('Scene title')\n",
    "    print(row['properties']['title'])\n",
    "    print('Scene geometry')\n",
    "    print(row['geometry'])\n",
    "    print('Scene id')\n",
    "    print(row['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1700322-d7d5-480a-b3a2-18a1673ab9aa",
   "metadata": {},
   "source": [
    "It's possible to sort results according to parameters such as acquisition date or cloud coverage. \n",
    "Use &sortParam=cloudCover or &sortParam={start_date} for this purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ccf39-468e-440c-a145-40748f5248f0",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "Write the Python code to search and download a satellite scene from another study area. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8868a1ac-990a-4c69-9743-9afdbd89ae64",
   "metadata": {},
   "source": [
    "## Chapter 2: Band combinations \n",
    "\n",
    "In this chapter we are going to show how to create different band combinations using stellite images and EarthPy Python library. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f203265-cf18-427b-b433-3c9dc7d7da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, download a Landsat scene \n",
    "# Use a granule obtained from the search with Earthaccess\n",
    "files = earthaccess.download(granules[0], \"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c20cf3-5f4a-4e1a-9d0a-003504bc09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library \n",
    "%pip install earthpy\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5876764-9943-474f-a798-df4f6ad21005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import earthpy as et\n",
    "import earthpy.spatial as es \n",
    "import earthpy.plot as ep\n",
    "\n",
    "# get bands path \n",
    "path_landsat_bands = glob('data/*.B*.tif')\n",
    "path_landsat_bands.sort()\n",
    "# stack bands \n",
    "stack, meta_data = es.stack(path_landsat_bands, nodata=-9999)\n",
    "# plot each separate band\n",
    "title = [\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\", \"B8\", \"B9\", \"B10\"]\n",
    "ep.plot_bands(stack, title=title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dca565-0b47-4555-98ff-929845c2e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram for each band  \n",
    "ep.hist(stack, bins=50, cols=3, title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93fca1-c557-49c0-b442-cfd49a421299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB Composites. True color composition\n",
    "\n",
    "# Create figure with one plot\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Plot red, green, and blue bands, respectively\n",
    "ep.plot_rgb(stack, \n",
    "            rgb=(3, 2, 1), \n",
    "            ax=ax, \n",
    "            title=\"Landsat RGB Image\",\n",
    "            stretch=True,\n",
    "            str_clip=0.2,\n",
    "           )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b20975-8728-4bdf-9ef6-e56e14b52eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB Composites. Fals color composition\n",
    "\n",
    "# Create figure with one plot\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Plot red, green, and blue bands, respectively\n",
    "ep.plot_rgb(stack, \n",
    "            rgb=(4, 3, 2), \n",
    "            ax=ax, \n",
    "            title=\"Landsat RGB Image\",\n",
    "            stretch=True,\n",
    "            str_clip=0.2,\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7f503-ba58-43a4-a300-012de8bb1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a cloud mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44043db-d309-47a8-ab5e-792be12174af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dcc18-eb99-484f-9fb5-c124f4c33365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from rasterio.plot import plotting_extent\n",
    "import earthpy.mask as em\n",
    "\n",
    "# Import the landsat qa layer\n",
    "with rio.open(\n",
    "    \"data/HLS.L30.T31TDG.2023214T102954.v2.0.Fmask.tif\"\n",
    ") as landsat_pre_cl:\n",
    "    landsat_qa = landsat_pre_cl.read(1)\n",
    "    landsat_ext = plotting_extent(landsat_pre_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0201a38-798e-42f2-9a6d-125a68bc1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot QA Band\n",
    "ep.plot_bands(\n",
    "    landsat_qa,\n",
    "    title=\"The Landsat QA Layer Comes with Landsat Data\\n It can be used to remove clouds and shadows\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48e280-8e5c-4e42-b1ef-ea99557cb655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array with mask values\n",
    "mask_values = [194]\n",
    "\n",
    "# Mask the data\n",
    "arr_ma = em.mask_pixels(stack, landsat_qa, vals=mask_values)\n",
    "\n",
    "# Plot mask\n",
    "ep.plot_rgb(\n",
    "    arr_ma, rgb=[4, 3, 2], title=\"Array with Clouds and Shadows Masked\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c241ccb4-510a-4cc1-8b53-d2a534daf60e",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "Write the Python code to create a natural color and false color composition with the images of your study area. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604df07-b575-4559-aa35-eba303bcf791",
   "metadata": {},
   "source": [
    "## Chapter 3: Vegetation indices\n",
    "\n",
    "In this chapter we are going to show how to calculate vegetation indexes like NDVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a74fd-de17-43be-b0f4-122470f35660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Difference Vegetation Index (NDVI\n",
    "# NDVI = (NIR ‚Äì Red) / (NIR + Red)\n",
    "\n",
    "# Calculate NDVI \n",
    "ndvi = es.normalized_diff(stack[4], stack[3])\n",
    "\n",
    "# Plot NDVI \n",
    "title = [\"Normalized Difference Vegetation Index (NDVI)\"]\n",
    "# Turn off bytescale scaling due to float values for NDVI\n",
    "ep.plot_bands(ndvi, cmap=\"RdYlGn\", cols=1, title=title, vmin=-1, vmax=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5238e143-76df-429b-9b55-c1913899a252",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "Try to calculate other indices like NDWI, NDSI... with images from your study area. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669170be-712e-4f93-ad95-3eff6ba6679b",
   "metadata": {},
   "source": [
    "## Chapter 4: Crop a scene \n",
    "\n",
    "In this chapter, you'll crop a remote sensing scene based on the bbox geometry of a vector layer. \n",
    "This process will be done with the Python libraries eartphy, rasterio and geopandas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262aafad-9baa-479d-8491-fcc7674e3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678bfd9-b135-402b-be24-29b223d2ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a shapefile with geopandas \n",
    "banyoles = gdp.read_file('./data/banyoles.shp')\n",
    "\n",
    "# Reproject to the same CRS as raster images \n",
    "with rio.open(path_landsat_bands[1]) as raster_crs: \n",
    "    raster_profile = raster_crs.profile\n",
    "    print(raster_profile)\n",
    "    banyoles_reprojected = banyoles.to_crs(raster_profile[\"crs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9679ad5b-8e8a-4127-a732-fbc2b9d90a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop bands with `crop_all`method. This method will allow to crop all bands at once. \n",
    "# The new bands will be identified by the suffix _crop\n",
    "\n",
    "output_directory = './data'\n",
    "\n",
    "crop_bands_path = es.crop_all(\n",
    "    path_landsat_bands, output_directory, banyoles_reprojected, overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724d962-e4d1-4c8b-82eb-d6e19fd23d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiband file from crop images \n",
    "\n",
    "# Create the bands stack \n",
    "path_landsat_bands_crop = glob('data/*B*_crop.tif')\n",
    "path_landsat_bands_crop.sort()\n",
    "\n",
    "print(path_landsat_bands_crop)\n",
    "\n",
    "# Prepare the metadata for the multiband file \n",
    "# The metadata for the multiband is the same as for a singleband, with exception of the number of bands. \n",
    "src = rio.open(path_landsat_bands_crop[1])\n",
    "meta = src.meta\n",
    "meta.update(count=len(path_landsat_bands_crop))\n",
    "\n",
    "# Create a destination file \n",
    "dst = rio.open('./data/landsat_crop.tif', 'w', **meta)\n",
    "\n",
    "# Iterate over the files, each time reading the current band and writing it to the destination file\n",
    "for index, filename in enumerate(path_landsat_bands_crop, start=1):\n",
    "    src = rio.open(filename)\n",
    "    dst.write(src.read(1), index)\n",
    "    src.close()\n",
    "\n",
    "# close the file connection, to make sure that all data have been written\n",
    "dst.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb2416-d664-41d7-a370-1370c8f7e253",
   "metadata": {},
   "source": [
    "## Chapter 5: Image classification using ML algorithms\n",
    "\n",
    "Image classification is a process to generate thematic cartography from remote sensing images.\n",
    "In this last chapter, we'll apply some machine learning algorithms to classify a remote sensing image using the Scikit-learn Python library.\n",
    "\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 60%\">\n",
    "       <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/1200px-Scikit_learn_logo_small.svg.png\", align=\"left\", width=\"250\">\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69aceb-ff05-4b44-a1b9-e84bebd5cf56",
   "metadata": {},
   "source": [
    "To carry out this exercise, some files are needed:\n",
    "\n",
    "- a multiband remote sensing image\n",
    "- a file with sampling points\n",
    "- a temporal file for sampling points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debaced-db86-4273-90c6-0a7b810a91f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the libraries\n",
    "\n",
    "%pip install fiona\n",
    "%pip install rasterio \n",
    "%pip install geopandas\n",
    "%pip install matplotlib\n",
    "%pip install seaborn \n",
    "%pip install numpy\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2d44d-d89b-46ea-83ec-3f16d13633e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282d941-15e0-430b-9d03-5c964aab3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files \n",
    "# The multiband image will be the Landsat stack we created before \n",
    "# Samples file, the points shapefile 'samples.shp'. \n",
    "# Temporal file, a shapefile with the name 'temp_sample.shp'.\n",
    "\n",
    "samples_loc = './data/samples.shp'\n",
    "temporal_sample_loc = './data/temp_sample.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492f722-a461-4ca9-96a4-c2ef47c27576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# land cover categories \n",
    "lulc_name = ['Water', 'Vegetation', 'Crops', 'Urban']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65368134-65fc-41b9-9058-66ea55cb8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an id to the samples file, and create the sample file\n",
    "\n",
    "# open samples file with geopandas \n",
    "points = gpd.read_file(samples_loc)\n",
    "# add a new id column with range of points\n",
    "points = points.assign(id = range(len(points)))\n",
    "# saving new points file with id \n",
    "points.to_file(temporal_sample_loc)\n",
    "# converting gdf to pandas dataframe and remove geometry \n",
    "points_df = pd.DataFrame(points.drop(columns = 'geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398aa65c-adfc-4ace-9cce-f48bb8ee1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas series\n",
    "# A pandas series is like a column in a table\n",
    "sampled = pd.Series()\n",
    "\n",
    "# Read input shapefile with fiona, and iterate over each feature \n",
    "# Extract the pixel value for each coordinate, and add this value to pandas serie. \n",
    "\n",
    "with fiona.open(temporal_sample_loc) as shp:\n",
    "    for feature in shp:\n",
    "        siteID = feature['properties']['id']\n",
    "        coords = feature['geometry']['coordinates']\n",
    "\n",
    "        # Rasterio to read pixel value at each coordinate \n",
    "        with rio.open('./data/landsat_crop.tif') as stack_src:\n",
    "            value = [v for v in stack_src.sample([coords])]\n",
    "\n",
    "        # Update pandads series \n",
    "        sampled.loc[siteID] = value\n",
    "\n",
    "# Convert pandas serie (unidimensional) to pandas dataframe (multidimensional)\n",
    "# In the series, each rown contains an array of values\n",
    "# We need to create a column for each band, with the registered values for each pixel\n",
    "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B9', 'B10', 'B11']\n",
    "bands_length = len(bands)\n",
    "df = pd.DataFrame(sampled.values.tolist(), index=sampled.index)\n",
    "df['id'] = df.index\n",
    "df = pd.DataFrame(df[0].values.tolist(), \n",
    "                   columns=bands)\n",
    "df['id'] = df.index\n",
    "\n",
    "# Merge the dataframes. df and points\n",
    "data = pd.merge(df, points_df, on='id')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7faee-d50d-443d-9d6e-91b9cfc5d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once features are sampled, separate data into independent variable (X) and dependent variable (Y)\n",
    "#x = data.iloc[:,0:len(bands)]\n",
    "x = data[bands]\n",
    "X = x.values\n",
    "#y = data.iloc[:,-1]\n",
    "y = data['labels']\n",
    "Y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268a471-b732-47e0-9b6a-1867d38c627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Scikit-learn train test to divide data into a 70/30 ratio (70% for training and 30% for testing)\n",
    "# test_size is the % of trainning data \n",
    "# stratify to select the representatory sample\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, stratify = Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4e4b4-4ee9-45cf-8dc3-1852913bffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainning the model \n",
    "# First start with the Support Vector Machine (SVM) model, a supervised learning model.  \n",
    "\n",
    "cName = 'SVM'\n",
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train) # train the model\n",
    "\n",
    "clf_pred = clf.predict(X_test) # predict with test data \n",
    "\n",
    "# Accuracy\n",
    "# Precision: Proportion of positive identifications was actually correct. Higher precision means that an algorithm returns more relevant results than irrelevant ones \n",
    "# Recall: a metric that measures how often a machine learning model correctly identifies positive instances (true positives) from all the actual positive samples in the dataset\n",
    "# F1-score: measures a model‚Äôs accuracy. It combines the precision and recall scores of a model.\n",
    "# Support: the number of true instances for each label\n",
    "print(f\"Accuracy {cName}: {accuracy_score(y_test, clf_pred)*100}\")\n",
    "print(classification_report(y_test, clf_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca76366-8434-4e90-83e6-7f7c0553d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and visualize the confusion matrix using Seaborn \n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, clf_pred)\n",
    "print('Confusion Matrix RF: \\n',cm)\n",
    "cm_percent = cm/np.sum(cm)\n",
    "\n",
    "plt.figure(figsize=(7, 7), facecolor='w', edgecolor='k')\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "sns.heatmap(cm_percent,\n",
    "            xticklabels=lulc_name,\n",
    "            yticklabels=lulc_name,\n",
    "            cmap=\"YlGn\",\n",
    "            annot=True,\n",
    "            fmt='.2%',\n",
    "            cbar=False,\n",
    "            linewidths=2,\n",
    "            linecolor='black')\n",
    "\n",
    "plt.title(cName)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "#plt.savefig(f'../figs/confusion_matrix_{cName}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368fc50-f8d2-4bfb-ba4d-a5277ce7a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and export the data \n",
    "# The most crucial step, to predict the full data using the trained model and export the results to Geotiff format.\n",
    "\n",
    "# First, read the original input image, and get different metadata properties (height, width, CRS...)\n",
    "cName = 'SVM'\n",
    "exp_name = f'./data/lulc_{cName}.tif'\n",
    "\n",
    "img = rio.open('./data/landsat_crop.tif')\n",
    "img_arr = img.read()\n",
    "bands = img_arr.shape[0]\n",
    "print(f'Height: {img_arr.shape[1]}\\nWidth: {img_arr.shape[2]}\\nBands: {img_arr.shape[0]}\\n')\n",
    "img_n = np.moveaxis(img_arr, 0, -1)\n",
    "img_n = img_n.reshape(-1, bands_length)\n",
    "print('reshaped full data shape  for prediction: ',img_n.shape)\n",
    "height = img.height\n",
    "width = img.width \n",
    "crs = img.crs\n",
    "transform = img.transform\n",
    "\n",
    "pred_full = clf.predict(img_n)\n",
    "print('Prediction Done, now exporting raster \\n')\n",
    "\n",
    "# Reshape the image \n",
    "img_reshape = pred_full.reshape(height, width)\n",
    "\n",
    "# Save outuput image\n",
    "out_raster = rio.open(exp_name,\n",
    "                      'w',\n",
    "                       driver='GTiff',\n",
    "                       height=height,\n",
    "                       width=width,\n",
    "                       count=1, # output band number\n",
    "                       dtype='uint8', #output data type\n",
    "                       crs=crs,\n",
    "                       transform = transform,\n",
    "                       nodata = 255 #nodata\n",
    "                       )\n",
    "\n",
    "out_raster.write(img_reshape, 1)\n",
    "out_raster.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef203ff4-6483-4f22-a500-ddd7b3e7c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results \n",
    "# Show image classification with custom legend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dcb19c-916b-4290-8238-e102dfb4ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install rioxarray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1afd64d-f7c7-48b3-949b-1b7f70d2c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import rioxarray as rxr\n",
    "\n",
    "# colors \n",
    "colors = [\"blue\", \"green\", \"yellow\", \"red\"]\n",
    "colors_cmap = ListedColormap(colors)\n",
    "\n",
    "# class names \n",
    "cat_names = [\n",
    "    \"Water\",\n",
    "    \"Vegetation\",\n",
    "    \"Crops\",\n",
    "    \"Urban\",\n",
    "]\n",
    "\n",
    "# get list of classes \n",
    "classes = np.unique(cat_names)\n",
    "classes = classes.tolist()\n",
    "\n",
    "# open raster as array\n",
    "xds = rxr.open_rasterio('./data/lulc_SVM.tif').squeeze()\n",
    "\n",
    "# plot data \n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "im = ax.imshow(xds, cmap=colors_cmap)\n",
    "\n",
    "# legend \n",
    "ep.draw_legend(im_ax=im, classes=classes,titles=cat_names)\n",
    "# title \n",
    "ax.set_title(\n",
    "    \"Land cover classification\",\n",
    "    fontsize=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe067fab-1557-48b1-ad84-b1981bf1b74a",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "Perform the same steps, but for different models. See the list of available classification models: https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "Generate the confusion matrix for each one, and compare the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799d57b-8186-4216-abb5-eab8cf91a81d",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "Waleed, M. (2023). Mastering Machine Learning based Land Use Classification with Python: A Comprehensive Guide! \n",
    "Bonny P. McClain. Python for Geospatial Data Analysis. O'Reilly "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
